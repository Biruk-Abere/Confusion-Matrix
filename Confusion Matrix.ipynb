{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnant</th>\n",
       "      <th>glucose</th>\n",
       "      <th>bp</th>\n",
       "      <th>skin</th>\n",
       "      <th>insulin</th>\n",
       "      <th>bmi</th>\n",
       "      <th>pedigree</th>\n",
       "      <th>age</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pregnant  glucose  bp  skin  insulin   bmi  pedigree  age  label\n",
       "0         6      148  72    35        0  33.6     0.627   50      1\n",
       "1         1       85  66    29        0  26.6     0.351   31      0\n",
       "2         8      183  64     0        0  23.3     0.672   32      1\n",
       "3         1       89  66    23       94  28.1     0.167   21      0\n",
       "4         0      137  40    35      168  43.1     2.288   33      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = 'pima-indians-diabetes.data'\n",
    "col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "pima=pd.read_csv(path , index_col = None , names = col_names)\n",
    "pima.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection\n",
    "feature_cols = ['pregnant' , 'insulin' , 'bmi' , 'age']\n",
    "X=pima[feature_cols]\n",
    "y = pima['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# LETS SPLIT THE ENTIRE DATASET IN TO TWO SPLITS\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train , X_test , y_train , y_test=train_test_split(X , y , random_state = 0)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logreg=LogisticRegression()\n",
    "logreg.fit(X_train , y_train)\n",
    "y_pred_class=logreg.predict(X_test)\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    130\n",
       "1     62\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every time we do the Classification accuracy , we need to compare with the null accuracy(choosing the highest frequent class as the testing set)\n",
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3229166666666667"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6770833333333333"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - y_test.mean() # we use this as our testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion :- 1) classification accuracy is good and easy to understand\n",
    "            #   2) but it can not tell us the underlying distribution of the response class\n",
    "            #   3) and also it does not tell us the type of error our classifier is making (confusion matrix will overcome this)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.confusion_matrix(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n",
      "15 118 12 47\n"
     ]
    }
   ],
   "source": [
    "confusion=metrics.confusion_matrix(y_test , y_pred_class)\n",
    "TP = confusion[1,1]\n",
    "TN = confusion[0,0]\n",
    "FP = confusion[0,1]\n",
    "FN = confusion[1,0]\n",
    "print(confusion)\n",
    "print(TP , TN , FP , FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metircs Computed From Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6927083333333334\n",
      "0.6927083333333334\n"
     ]
    }
   ],
   "source": [
    "# 1) classification metrics:- \n",
    "print((TN+TP)/float(TN+TP+FN+FP))\n",
    "print(metrics.accuracy_score(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3072916666666667\n",
      "0.30729166666666663\n"
     ]
    }
   ],
   "source": [
    "# 2) Classification Error:-\n",
    "print((FP+FN)/float(TN+TP+FP+FN))\n",
    "print(1-metrics.accuracy_score(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24193548387096775\n",
      "0.24193548387096775\n"
     ]
    }
   ],
   "source": [
    "# 3) Sensitivity:- when our actual value is positive , how often is our classifier predicted correct\n",
    "# it also called True Positive Rate or recall\n",
    "# how sensitive is our classifier is positive instances\n",
    "print((TP/float(TP+FN)))\n",
    "print(metrics.recall_score(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9076923076923077\n"
     ]
    }
   ],
   "source": [
    "# 4) Specificity:- When our actual value is negative , how often is our classifier predicted correct\n",
    "# how Specific or selective is our classifier for negative instances\n",
    "print((TN) / float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So our problem is more Specificity than Sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09230769230769231\n",
      "0.09230769230769231\n"
     ]
    }
   ],
   "source": [
    "# 5) False Positive Rate :- This is the reverse of Specificity , when our actual is negative , how often is our classifier predicted incorrect\n",
    "print((FP) / float(TN+FP))\n",
    "print(1-(TN/float(TN+FP))) # 1- the Specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5555555555555556\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "# 6) Precession:- When a postive value is predited how often the prediction is correct\n",
    "# how precise is our classifier for positive instances\n",
    "print(TP/float(FP+TP))\n",
    "print(metrics.precision_score(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion for confuson matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusion:- \n",
    "   # 1) Confusion Matrix gives you a more picture of how your classifier is performing\n",
    "   # 2) Also allows you to compute various classification metrics and these also used to guide for a model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Which Metrics Should We Focus On"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choice of the metric depends on your business objective For Example :-\n",
    "# 1) Spam Filter (the Observation is Email) :- Positive(1) for Spam and Negative(0) for a ham \n",
    "        # we will optimize for Precession or Specificity because False negative(Spam go to the inbox)are more acceptable than False\n",
    "        # Positives(Non-Spam is caught by the spam filter), We need to minimize the False Positive by using Specificity and Precession\n",
    "# 2) Fraudulent Transaction Detector (The Observation is Transaction):- Positive(1) for fraud and negative(0) for a normal transaction\n",
    "        # Optimize for Sensitivity because Flase Positives (Normal Transaction that are flagged as FRAUD) are more acceptable than false negatives(Fraud Transactions that are not detected)\n",
    "        # we need to minimize Flase Negative By using Sensitivity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusing The Classification Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# print the predicted responses\n",
    "print(logreg.predict(X_test)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.63247571 0.36752429]\n",
      " [0.71643656 0.28356344]\n",
      " [0.71104114 0.28895886]\n",
      " [0.5858938  0.4141062 ]\n",
      " [0.84103973 0.15896027]\n",
      " [0.82934844 0.17065156]\n",
      " [0.50110974 0.49889026]\n",
      " [0.48658459 0.51341541]\n",
      " [0.72321388 0.27678612]\n",
      " [0.32810562 0.67189438]]\n"
     ]
    }
   ],
   "source": [
    "# lets check the probabilities\n",
    "print(logreg.predict_proba(X_test)[0:10 , :]) # 10 rows and all of the column of the response values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36752429 0.28356344 0.28895886 0.4141062  0.15896027 0.17065156\n",
      " 0.49889026 0.51341541 0.27678612 0.67189438]\n"
     ]
    }
   ],
   "source": [
    "# by default the threshold value is 0.5\n",
    "print(logreg.predict_proba(X_test)[0:10 , 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = logreg.predict_proba(X_test)[: , 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Frequency')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lets plot using histogram\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(y_pred_proba , bins = 8)\n",
    "plt.xlim(0,1)\n",
    "plt.title('Histogram Of Predicted Probabilities')\n",
    "plt.xlabel('Probabilites of Predicted Response')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decrease Threshold To increase Sensitivity and decrease the specificity\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class=binarize([y_pred_proba] , 0.3)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36752429 0.28356344 0.28895886 0.4141062  0.15896027 0.17065156\n",
      " 0.49889026 0.51341541 0.27678612 0.67189438]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_proba[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[118  12]\n",
      " [ 47  15]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 1., 0., 0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first ten predicted classes\n",
    "y_pred_class[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80 50]\n",
      " [16 46]]\n"
     ]
    }
   ],
   "source": [
    "confusion=metrics.confusion_matrix(y_test , y_pred_class)\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 80 16 50\n"
     ]
    }
   ],
   "source": [
    "TP=confusion[1,1]\n",
    "TN=confusion[0,0]\n",
    "FN=confusion[1,0]\n",
    "FP=confusion[0,1]\n",
    "print(TP , TN , FN , FP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7419354838709677\n",
      "0.7419354838709677\n"
     ]
    }
   ],
   "source": [
    "# Sensitivity:-# sensitivity has increased (used to be 0.24)\n",
    "print(TP/float(TP+FN))\n",
    "print(metrics.recall_score(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6153846153846154\n"
     ]
    }
   ],
   "source": [
    "# Specificity:- # specificity has decreased (used to be 0.91)\n",
    "print(TN / float(TN+FP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[129   1]\n",
      " [ 58   4]]\n",
      "4 129 1 58\n"
     ]
    }
   ],
   "source": [
    "# Increase the Threshold , To increase the Specificity and the Decrease the Sensitivity\n",
    "from sklearn.preprocessing import binarize\n",
    "y_pred_class=binarize([y_pred_proba] , 0.7)[0]\n",
    "confusion=metrics.confusion_matrix(y_test , y_pred_class)\n",
    "TP=confusion[1,1]\n",
    "TN=confusion[0,0]\n",
    "FP=confusion[0,1]\n",
    "FN=confusion[1,0]\n",
    "print(confusion)\n",
    "print(TP , TN , FP , FN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_class[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36752429 0.28356344 0.28895886 0.4141062  0.15896027 0.17065156\n",
      " 0.49889026 0.51341541 0.27678612 0.67189438 0.35755557 0.74087965\n",
      " 0.36050235 0.23012363 0.42654231 0.19103515 0.45763601 0.1190141\n",
      " 0.43928953 0.36961151]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_proba[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06451612903225806\n",
      "0.06451612903225806\n"
     ]
    }
   ],
   "source": [
    "# Senstivity:-\n",
    "print(TP / float(TP+FN))\n",
    "print(metrics.recall_score(y_test , y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9923076923076923\n"
     ]
    }
   ],
   "source": [
    "# Specificity:- the specificity with the default threshold is 0.9076923076923077\n",
    "print(TN/float(TN+FP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SO IT DEPENDS ON OUR BUSSINESS OBJECTIBVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the last METHOD to select the model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
